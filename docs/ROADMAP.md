# Roadmap Completo: Sistema RAG para Crypto Knowledge Platform

## Visi√≥n General

Este documento detalla el roadmap completo para implementar un sistema de chatbot conversacional con RAG (Retrieval-Augmented Generation) orientado a consultas sobre criptomonedas. El sistema sigue una arquitectura basada en Clean Architecture y Domain-Driven Design, organizada en Bounded Contexts.

---

## Estado Actual

### ‚úÖ Implementado

#### Content Ingestion Context

- **Estado**: Completamente implementado
- **Responsabilidades**:
  - Ingesta multi-fuente (web scraping, RSS, social media, PDF, OCR, Wikipedia)
  - Normalizaci√≥n de contenido
  - Deduplicaci√≥n
  - Extracci√≥n de metadata b√°sica
  - Gesti√≥n de jobs de ingesta
  - Configuraci√≥n de fuentes

- **Componentes Clave**:
  - Aggregates: `ContentItem`, `IngestionJob`, `SourceConfiguration`
  - Value Objects: `ContentHash`, `SourceType`, `IngestionStatus`, `AssetTag`
  - Domain Services: `ContentHashGenerator`, `DuplicateDetectionService`
  - Source Adapters: Web, RSS, Social Media, PDF, OCR, Wikipedia

---

## Bounded Contexts Pendientes

### üöß Contextos por Implementar

1. **Refinement** (Fase 1) - Refinar contenido crudo
2. **Embedding & Indexing** (Fase 2) - Vectorizaci√≥n
3. **Knowledge Retrieval** (Fase 3) - B√∫squeda sem√°ntica
4. **RAG Assistant** (Fase 4) - Chat conversacional
5. **Signals & Analytics** (Fase 5 - Opcional)
6. **Identity & Configuration** (Fase 6 - Opcional)

---

## Fase 1: Refinement Context

### üìÖ Timeline: 4-6 semanas

### üéØ Objetivo

Refinar contenido crudo hasta que sea √∫til y significativo: chunks sem√°nticos enriquecidos, listos para ser vectorizados e indexados.

### üí° Por Qu√© "Refinement"

- Lenguaje ubicuo natural: "Este contenido pas√≥ por Refinement"
- Implica mejora de calidad, no solo transformaci√≥n
- Agn√≥stico de implementaci√≥n (no asume documentos, IA, etc.)
- Ver: `docs/refinement/00-WHY-REFINEMENT.md`

### üì¶ Responsabilidades

#### Core Responsibilities

1. **Chunking Sem√°ntico**
   - Dividir documentos en fragmentos coherentes
   - Preservar contexto entre chunks
   - Mantener integridad sem√°ntica
   - Configuraci√≥n flexible de tama√±o

2. **Enriquecimiento de Contenido**
   - Extracci√≥n de entidades crypto (tokens, exchanges, blockchains)
   - Identificaci√≥n de eventos relevantes
   - Detecci√≥n de temporalidad
   - Clasificaci√≥n de tipo de contenido

3. **Metadata Generation**
   - Generaci√≥n de hashes de chunks
   - Timestamps y versionado
   - Relaciones entre chunks
   - Scores de calidad

4. **Content Validation**
   - Validaci√≥n de calidad m√≠nima
   - Detecci√≥n de contenido spam
   - Filtrado de contenido irrelevante

### üèóÔ∏è Arquitectura

#### Aggregates

- **`ProcessedDocument`** (Aggregate Root)
  - Representa un documento procesado completo
  - Contiene colecci√≥n de chunks
  - Mantiene metadata del documento original
  - Gestiona versionado

#### Entities

- **`DocumentChunk`**
  - Fragmento sem√°ntico del documento
  - Posici√≥n y contexto
  - Metadata espec√≠fica del chunk

#### Value Objects

- **`ChunkHash`** - Hash √∫nico del chunk
- **`ChunkPosition`** - Posici√≥n en el documento original
- **`CryptoEntity`** - Entidad crypto extra√≠da (token, exchange, etc.)
- **`TemporalMarker`** - Marcador temporal del contenido
- **`ContentQualityScore`** - Score de calidad del contenido

#### Domain Services

- **`SemanticChunker`** - Chunking inteligente
- **`CryptoEntityExtractor`** - Extracci√≥n de entidades crypto
- **`TemporalAnalyzer`** - An√°lisis de temporalidad
- **`ContentQualityAnalyzer`** - An√°lisis de calidad

### üîó Integraciones

#### Input

- **Content Ingestion Context**
  - Consume: `ContentItem` (contenido crudo)
  - Via: Domain Events (`ContentIngestedEvent`)

#### Output

- **Embedding & Indexing Context**
  - Produce: `ProcessedDocument` con chunks
  - Via: Domain Events (`DocumentProcessedEvent`)

### üìä M√©tricas Clave

- Chunks generados por documento
- Tiempo de procesamiento
- Entidades extra√≠das por chunk
- Score promedio de calidad
- Tasa de rechazo de contenido

### üõ†Ô∏è Stack T√©cnico

#### Chunking

- **LangChain Text Splitters**
  - `RecursiveCharacterTextSplitter` (general)
  - `MarkdownTextSplitter` (markdown)
  - `CodeTextSplitter` (c√≥digo)

#### Entity Extraction

- **NER (Named Entity Recognition)**
  - spaCy (local)
  - OpenAI GPT-4o-mini (cloud)
  - Custom regex patterns para crypto

#### Temporal Analysis

- **Date Extraction**
  - chrono-node
  - Custom temporal parsers

### üìã Tareas Principales

#### 1. Domain Layer (2 semanas)

- [ ] Definir aggregates y entities
- [ ] Implementar value objects
- [ ] Crear domain services
- [ ] Definir interfaces (ports)
- [ ] Implementar domain events
- [ ] Tests unitarios de dominio

#### 2. Application Layer (1 semana)

- [ ] Commands: ProcessDocument, ReprocessDocument
- [ ] Queries: GetProcessedDocument, GetChunksByDocument
- [ ] Event handlers
- [ ] Use case orchestration
- [ ] Tests de application layer

#### 3. Infrastructure Layer (2 semanas)

- [ ] Repository implementations (TypeORM)
- [ ] Chunking service implementations
- [ ] Entity extraction implementations
- [ ] Temporal analysis implementations
- [ ] Database migrations
- [ ] Tests de integraci√≥n

#### 4. API Layer (1 semana)

- [ ] CLI commands (process, reprocess, status)
- [ ] HTTP controllers (opcional)
- [ ] DTOs
- [ ] Tests end-to-end

### üéØ Entregables

1. **Bounded Context Completo**
   - Domain, App, Infra, API layers
   - Tests (unit, integration, e2e)
   - Migrations

2. **Documentaci√≥n**
   - README del contexto
   - Diagramas de arquitectura
   - Gu√≠a de uso

3. **CLI Commands**
   ```bash
   npm run cli process:document --content-id <id>
   npm run cli process:batch --source <source>
   npm run cli process:status --job-id <id>
   ```

### ‚úÖ Criterios de √âxito

- [ ] Procesa 100+ documentos sin errores
- [ ] Genera chunks sem√°nticamente coherentes
- [ ] Extrae entidades crypto con >80% precisi√≥n
- [ ] Tiempo de procesamiento <5s por documento
- [ ] Cobertura de tests >80%

---

## Fase 2: Embedding & Indexing Context

### üìÖ Timeline: 3-4 semanas

### üéØ Objetivo

Generar embeddings vectoriales de los chunks procesados e indexarlos en una base de datos vectorial para b√∫squeda sem√°ntica eficiente.

### üì¶ Responsabilidades

#### Core Responsibilities

1. **Embedding Generation**
   - Generar vectores de chunks
   - Soporte multi-modelo (OpenAI, Cohere, local)
   - Batch processing
   - Retry y error handling

2. **Vector Indexing**
   - Almacenar embeddings en Vector DB
   - Indexaci√≥n incremental
   - Actualizaci√≥n de √≠ndices
   - Eliminaci√≥n de embeddings obsoletos

3. **Embedding Management**
   - Versionado de embeddings
   - Tracking de modelos usados
   - M√©tricas de calidad
   - Cache de embeddings

4. **Index Optimization**
   - Configuraci√≥n de √≠ndices
   - Optimizaci√≥n de b√∫squeda
   - Mantenimiento de √≠ndices

### üèóÔ∏è Arquitectura

#### Aggregates

- **`EmbeddedChunk`** (Aggregate Root)
  - Chunk + embedding vector
  - Metadata del modelo usado
  - Versi√≥n del embedding
  - Timestamp de generaci√≥n

#### Value Objects

- **`EmbeddingVector`** - Vector num√©rico (float[])
- **`EmbeddingModel`** - Modelo usado (OpenAI, Cohere, etc.)
- **`EmbeddingVersion`** - Versi√≥n del embedding
- **`VectorDimension`** - Dimensi√≥n del vector

#### Domain Services

- **`EmbeddingGenerator`** - Generaci√≥n de embeddings
- **`IndexManager`** - Gesti√≥n de √≠ndices
- **`EmbeddingVersionManager`** - Versionado

### üîó Integraciones

#### Input

- **Document Processing Context**
  - Consume: `ProcessedDocument` con chunks
  - Via: Domain Events (`DocumentProcessedEvent`)

#### Output

- **Knowledge Retrieval Context**
  - Produce: Embeddings indexados
  - Via: Vector DB queries

### üõ†Ô∏è Stack T√©cnico

#### Embedding Providers

- **OpenAI** - `text-embedding-3-small` (1536 dims)
- **Cohere** - `embed-multilingual-v3.0`
- **Local** - `all-MiniLM-L6-v2` (384 dims)

#### Vector Databases

- **Opci√≥n A**: Qdrant (recomendado)
  - Open source
  - Alta performance
  - Filtros avanzados
  - Docker-friendly

- **Opci√≥n B**: Pinecone
  - Serverless
  - Escalable
  - Managed service

- **Opci√≥n C**: pgvector
  - PostgreSQL extension
  - Simplifica stack
  - Bueno para MVP

### üìã Tareas Principales

#### 1. Domain Layer (1 semana)

- [ ] Definir aggregates y value objects
- [ ] Crear domain services
- [ ] Definir interfaces para providers
- [ ] Implementar domain events
- [ ] Tests unitarios

#### 2. Application Layer (1 semana)

- [ ] Commands: GenerateEmbedding, ReindexChunk
- [ ] Queries: GetEmbedding, SearchSimilar
- [ ] Event handlers
- [ ] Batch processing logic
- [ ] Tests

#### 3. Infrastructure Layer (1.5 semanas)

- [ ] Embedding provider implementations
- [ ] Vector DB implementations
- [ ] Repository implementations
- [ ] Cache layer (Redis)
- [ ] Migrations
- [ ] Tests de integraci√≥n

#### 4. API Layer (0.5 semanas)

- [ ] CLI commands
- [ ] HTTP endpoints (opcional)
- [ ] Tests e2e

### üéØ Entregables

1. **Bounded Context Completo**
2. **Vector DB Setup**
   - Docker compose
   - Configuraci√≥n
   - Scripts de inicializaci√≥n

3. **CLI Commands**
   ```bash
   npm run cli embed:generate --chunk-id <id>
   npm run cli embed:batch --document-id <id>
   npm run cli embed:reindex --all
   npm run cli embed:search --query "bitcoin price"
   ```

### ‚úÖ Criterios de √âxito

- [ ] Genera embeddings para 1000+ chunks
- [ ] Indexaci√≥n <1s por chunk
- [ ] B√∫squeda sem√°ntica <100ms
- [ ] Soporte para m√∫ltiples modelos
- [ ] Cobertura de tests >80%

---

## Fase 3: Knowledge Retrieval Context

### üìÖ Timeline: 4-5 semanas

### üéØ Objetivo

Implementar b√∫squeda sem√°ntica avanzada con re-ranking basado en signals, filtros temporales y por entidades crypto.

### üì¶ Responsabilidades

#### Core Responsibilities

1. **Semantic Search**
   - B√∫squeda por similitud vectorial
   - Top-K retrieval
   - Threshold de relevancia
   - Deduplicaci√≥n de resultados

2. **Hybrid Search**
   - Combinaci√≥n de b√∫squeda sem√°ntica + keyword (BM25)
   - Fusi√≥n de scores
   - Optimizaci√≥n de pesos

3. **Re-Ranking**
   - Re-ranking basado en signals
   - Scoring multi-dimensional
   - Explicabilidad de scores
   - Pluggable rerankers

4. **Advanced Filtering**
   - Filtros temporales (fecha, rango)
   - Filtros por entidades (token, exchange)
   - Filtros por fuente
   - Filtros por calidad

5. **Query Understanding**
   - An√°lisis de intenci√≥n
   - Extracci√≥n de entidades de la query
   - Detecci√≥n de temporalidad
   - Expansi√≥n de queries

### üèóÔ∏è Arquitectura

#### Aggregates

- **`SearchQuery`** (Aggregate Root)
  - Query del usuario
  - Filtros aplicados
  - Resultados obtenidos
  - Metadata de b√∫squeda

#### Entities

- **`SearchResult`**
  - Chunk recuperado
  - Score de relevancia
  - Explicaci√≥n del score
  - Metadata

#### Value Objects

- **`QueryIntent`** - Intenci√≥n de la query
- **`RelevanceScore`** - Score de relevancia (0-1)
- **`TemporalFilter`** - Filtro temporal
- **`EntityFilter`** - Filtro por entidad
- **`SearchMetrics`** - M√©tricas de b√∫squeda

#### Domain Services

- **`SemanticSearchService`** - B√∫squeda sem√°ntica
- **`HybridSearchService`** - B√∫squeda h√≠brida
- **`ReRankingService`** - Re-ranking de resultados
- **`QueryAnalyzer`** - An√°lisis de queries
- **`ResultFusionService`** - Fusi√≥n de resultados

### üîó Integraciones

#### Input

- **Embedding & Indexing Context**
  - Consume: Embeddings indexados
  - Via: Vector DB queries

- **Signals & Analytics Context** (opcional)
  - Consume: Signals para re-ranking
  - Via: Read repositories

#### Output

- **RAG Assistant Context**
  - Produce: Documentos rankeados
  - Via: Domain services

### üõ†Ô∏è Stack T√©cnico

#### Search

- **Vector Search**: Qdrant/Pinecone native
- **Keyword Search**: BM25 (Elasticsearch o custom)
- **Hybrid**: Reciprocal Rank Fusion (RRF)

#### Re-Ranking

- **Cohere Rerank API** (cloud)
- **Cross-Encoder models** (local)
- **Custom scoring** (signals-based)

#### Query Analysis

- **LLM-based** (GPT-4o-mini)
- **Rule-based** (regex + NER)

### üìã Tareas Principales

#### 1. Domain Layer (1.5 semanas)

- [ ] Definir aggregates y entities
- [ ] Implementar value objects
- [ ] Crear domain services
- [ ] Definir interfaces
- [ ] Tests unitarios

#### 2. Application Layer (1 semana)

- [ ] Queries: SemanticSearch, HybridSearch
- [ ] Commands: SaveSearchQuery
- [ ] Query handlers
- [ ] Tests

#### 3. Infrastructure Layer (2 semanas)

- [ ] Vector search implementation
- [ ] Keyword search implementation
- [ ] Hybrid search implementation
- [ ] Re-ranking implementations
- [ ] Query analyzer implementations
- [ ] Tests de integraci√≥n

#### 4. API Layer (0.5 semanas)

- [ ] CLI commands
- [ ] HTTP endpoints
- [ ] Tests e2e

### üéØ Entregables

1. **Bounded Context Completo**
2. **Search Configurations**
   - Configuraci√≥n de √≠ndices
   - Configuraci√≥n de re-rankers
   - Configuraci√≥n de filtros

3. **CLI Commands**
   ```bash
   npm run cli search:semantic --query "bitcoin trends"
   npm run cli search:hybrid --query "ethereum price" --date-range "last-week"
   npm run cli search:filter --entity "BTC" --source "twitter"
   ```

### ‚úÖ Criterios de √âxito

- [ ] B√∫squeda sem√°ntica <100ms
- [ ] Precision@5 >70%
- [ ] Recall@10 >80%
- [ ] Re-ranking mejora relevancia >20%
- [ ] Filtros funcionan correctamente
- [ ] Cobertura de tests >80%

---

## Fase 4: RAG Assistant Context

### üìÖ Timeline: 5-6 semanas

### üéØ Objetivo

Implementar chatbot conversacional con RAG que responde preguntas sobre crypto con citaciones de fuentes.

### üì¶ Responsabilidades

#### Core Responsibilities

1. **Conversation Management**
   - Crear y gestionar sesiones
   - Persistir historial
   - Mantener contexto multi-turno
   - Gestionar referencias anaf√≥ricas

2. **RAG Orchestration**
   - Coordinar retrieval
   - Construir contexto para LLM
   - Generar respuestas
   - Incluir citaciones

3. **Query Understanding**
   - Reformular queries con historial
   - Extraer intenci√≥n
   - Identificar entidades y temporalidad

4. **Response Generation**
   - Generar respuestas contextualizadas
   - Formatear con citaciones
   - Controlar longitud y detalle
   - Streaming de respuestas

5. **Conversational Memory**
   - Short-term (sesi√≥n actual)
   - Long-term (preferencias)
   - Checkpointing

### üèóÔ∏è Arquitectura

#### Aggregates

- **`Conversation`** (Aggregate Root)
  - Sesi√≥n conversacional
  - Colecci√≥n de mensajes
  - Estado de la conversaci√≥n
  - Metadata

#### Entities

- **`Message`**
  - Mensaje individual
  - Role (user/assistant/system)
  - Contenido
  - Citaciones
  - Timestamp

#### Value Objects

- **`ConversationId`** - ID √∫nico de conversaci√≥n
- **`MessageRole`** - Role del mensaje
- **`QueryIntent`** - Intenci√≥n de la query
- **`SourceCitation`** - Citaci√≥n de fuente
- **`ConversationStatus`** - Estado (active, ended)

#### Domain Services

- **`QueryUnderstandingService`** - An√°lisis de queries
- **`ContextBuilderService`** - Construcci√≥n de contexto
- **`ResponseFormatterService`** - Formateo de respuestas
- **`ConversationMemoryService`** - Gesti√≥n de memoria

### üîó Integraciones

#### Input

- **Knowledge Retrieval Context**
  - Consume: Documentos rankeados
  - Via: Domain services

#### Output

- **CLI/API**
  - Produce: Respuestas conversacionales
  - Via: Controllers

### üõ†Ô∏è Stack T√©cnico

#### LLM Orchestration

- **LangChain** - Framework principal
- **LangGraph** - State management
- **LangSmith** - Observability

#### LLM Providers

- **OpenAI** - GPT-4o, GPT-4o-mini
- **Anthropic** - Claude 3.5 Sonnet
- **Ollama** - Llama 3, Mistral (local)

#### Memory

- **Redis** - Short-term memory
- **PostgreSQL** - Long-term persistence

#### CLI

- **Commander** - CLI framework
- **Ink** - Interactive UI (opcional)

### üìã Tareas Principales

#### 1. Domain Layer (2 semanas)

- [ ] Definir aggregates y entities
- [ ] Implementar value objects
- [ ] Crear domain services
- [ ] Definir interfaces (LLM, Memory, Retrieval)
- [ ] Implementar domain events
- [ ] Tests unitarios

#### 2. Application Layer (1.5 semanas)

- [ ] Commands: StartConversation, SendMessage, EndConversation
- [ ] Queries: GetConversationHistory, GetActiveConversations
- [ ] Event handlers
- [ ] RAG pipeline orchestration
- [ ] Tests

#### 3. Infrastructure Layer (2 semanas)

- [ ] LLM provider implementations
- [ ] Memory implementations (Redis)
- [ ] Repository implementations
- [ ] Retrieval adapter
- [ ] LangChain integration
- [ ] Tests de integraci√≥n

#### 4. API Layer (1 semana)

- [ ] CLI interactive chat
- [ ] CLI single query
- [ ] HTTP endpoints
- [ ] WebSocket (streaming)
- [ ] Tests e2e

### üéØ Entregables

1. **Bounded Context Completo**
2. **LangChain Integration**
   - RAG chains
   - History-aware retriever
   - Prompt templates

3. **CLI Commands**

   ```bash
   # Interactive chat
   npm run cli chat:start

   # Single query
   npm run cli chat:ask "What happened with Bitcoin this week?"

   # History
   npm run cli chat:history
   npm run cli chat:export --format json
   ```

4. **HTTP API**
   ```
   POST /api/conversations
   POST /api/conversations/:id/messages
   GET /api/conversations/:id
   GET /api/conversations/:id/messages
   ```

### ‚úÖ Criterios de √âxito

- [ ] Responde queries con contexto conversacional
- [ ] Incluye citaciones de fuentes
- [ ] Latencia <3s por respuesta
- [ ] Streaming funciona correctamente
- [ ] Memoria conversacional persiste
- [ ] CLI interactivo funcional
- [ ] API HTTP funcional
- [ ] Cobertura de tests >80%

---

## Fase 5: Signals & Analytics Context (Opcional)

### üìÖ Timeline: 3-4 semanas

### üéØ Objetivo

Detectar tendencias, calcular relevancia din√°mica y generar signals para mejorar el re-ranking.

### üì¶ Responsabilidades

#### Core Responsibilities

1. **Trend Detection**
   - Detectar tendencias emergentes
   - Calcular velocidad de cambio
   - Identificar picos de actividad

2. **Signal Generation**
   - Volumen de menciones
   - Cambios abruptos
   - Autoridad de fuente
   - Recencia

3. **Relevance Scoring**
   - Scoring din√°mico
   - Agregaci√≥n temporal
   - Scoring por activo

4. **Analytics**
   - M√©tricas agregadas
   - Reportes
   - Visualizaciones (opcional)

### üèóÔ∏è Arquitectura

#### Aggregates

- **`Signal`** (Aggregate Root)
- **`TrendAnalysis`**

#### Value Objects

- **`SignalType`**
- **`SignalStrength`**
- **`TrendDirection`**

#### Domain Services

- **`TrendDetectionService`**
- **`SignalAggregationService`**
- **`RelevanceScoringService`**

### üîó Integraciones

#### Input

- **Content Ingestion Context** - Contenido nuevo
- **Document Processing Context** - Chunks procesados

#### Output

- **Knowledge Retrieval Context** - Signals para re-ranking

### ‚úÖ Criterios de √âxito

- [ ] Detecta tendencias en tiempo real
- [ ] Genera signals √∫tiles para re-ranking
- [ ] Mejora relevancia de b√∫squeda >15%

---

## Fase 6: Identity & Configuration Context (Opcional)

### üìÖ Timeline: 2-3 semanas

### üéØ Objetivo

Gestionar configuraci√≥n, API keys, perfiles de usuario y feature flags.

### üì¶ Responsabilidades

1. **Configuration Management**
2. **API Key Management**
3. **User Profiles**
4. **Feature Flags**
5. **Authentication** (para API)

---

## Resumen del Roadmap

### Timeline Total: 18-24 semanas (4.5-6 meses)

```
Mes 1-1.5: Document Processing
Mes 2-2.5: Embedding & Indexing
Mes 3-4: Knowledge Retrieval
Mes 4.5-6: RAG Assistant
Mes 6+ (Opcional): Signals & Analytics, Identity & Configuration
```

### Dependencias Cr√≠ticas

```
Content Ingestion (‚úÖ Implementado)
    ‚Üì
Document Processing (Fase 1)
    ‚Üì
Embedding & Indexing (Fase 2)
    ‚Üì
Knowledge Retrieval (Fase 3)
    ‚Üì
RAG Assistant (Fase 4)
    ‚Üì
Signals & Analytics (Fase 5 - Opcional)
Identity & Configuration (Fase 6 - Opcional)
```

### Hitos Clave

- **Hito 1** (Semana 6): Document Processing funcional
- **Hito 2** (Semana 10): Embeddings indexados y buscables
- **Hito 3** (Semana 15): B√∫squeda sem√°ntica con re-ranking
- **Hito 4** (Semana 21): Chatbot RAG funcional (MVP)
- **Hito 5** (Semana 24+): Sistema completo con analytics

### Recursos Necesarios

#### Desarrollo

- 1 desarrollador full-time
- Conocimientos: TypeScript, NestJS, DDD, LangChain, Vector DBs

#### Infraestructura

- PostgreSQL (metadata)
- Redis (cache/memory)
- Vector DB (Qdrant/Pinecone)
- LLM API (OpenAI/Anthropic)
- Embedding API (OpenAI/Cohere)

#### Costos Estimados (Mensual)

- LLM API: $50-200
- Embedding API: $20-100
- Vector DB: $0-100 (Qdrant local vs Pinecone)
- Hosting: $50-200
- **Total**: $120-600/mes

---

## Estrategias de Implementaci√≥n

### Opci√≥n A: Secuencial (Recomendada)

Implementar cada fase en orden, sin mocks.

**Pros**:

- ‚úÖ Arquitectura s√≥lida
- ‚úÖ Sin deuda t√©cnica
- ‚úÖ Tests reales

**Contras**:

- ‚ö†Ô∏è M√°s tiempo hasta MVP
- ‚ö†Ô∏è Requiere paciencia

### Opci√≥n B: Fast-Track con Mocks

Saltar a RAG Assistant (Fase 4) mockeando Fases 1-3.

**Pros**:

- ‚úÖ MVP r√°pido (6-8 semanas)
- ‚úÖ Validaci√≥n temprana

**Contras**:

- ‚ö†Ô∏è Deuda t√©cnica
- ‚ö†Ô∏è Refactoring despu√©s
- ‚ö†Ô∏è Tests menos confiables

### Opci√≥n C: H√≠brida

Implementar Fase 1 (Document Processing) + Fase 4 (RAG Assistant) con mocks para Fases 2-3.

**Pros**:

- ‚úÖ Balance entre velocidad y calidad
- ‚úÖ Fundaci√≥n s√≥lida (chunking)
- ‚úÖ MVP en 10-12 semanas

**Contras**:

- ‚ö†Ô∏è Algo de deuda t√©cnica
- ‚ö†Ô∏è Refactoring parcial

---

## Recomendaci√≥n Final

### Para MVP R√°pido (2-3 meses)

**Opci√≥n C: H√≠brida**

1. Implementar Document Processing (Fase 1)
2. Implementar RAG Assistant (Fase 4) con mocks
3. Backfill Embedding & Indexing (Fase 2)
4. Backfill Knowledge Retrieval (Fase 3)

### Para Arquitectura S√≥lida (4-6 meses)

**Opci√≥n A: Secuencial**

1. Document Processing
2. Embedding & Indexing
3. Knowledge Retrieval
4. RAG Assistant
5. Signals & Analytics (opcional)

---

## Pr√≥ximos Pasos

1. **Decidir estrategia**: Secuencial vs Fast-Track vs H√≠brida
2. **Crear primer spec**: Document Processing o RAG Assistant
3. **Setup de infraestructura**: PostgreSQL, Redis, Vector DB
4. **Comenzar implementaci√≥n**

---

## Ap√©ndice: Bounded Context Names

### Nombres Finales Propuestos

| Bounded Context          | Nombre Propuesto      | Alternativas                                |
| ------------------------ | --------------------- | ------------------------------------------- |
| Refinement               | `refinement`          | `content-refinement`, `enrichment`          |
| Embedding & Indexing     | `embedding-indexing`  | `vectorization`, `indexing`                 |
| Knowledge Retrieval      | `knowledge-retrieval` | `search`, `retrieval`                       |
| RAG Assistant            | `rag-assistant`       | `conversational-rag`, `knowledge-assistant` |
| Signals & Analytics      | `signals-analytics`   | `analytics`, `trends`                       |
| Identity & Configuration | `identity-config`     | `configuration`, `settings`                 |

### Justificaci√≥n de Nombres

- **`refinement`**: Refina contenido crudo (forma, significado, calidad). Ver `docs/refinement/00-WHY-REFINEMENT.md`
- **`embedding-indexing`**: Combina las dos responsabilidades principales
- **`knowledge-retrieval`**: Enfocado en recuperaci√≥n de conocimiento
- **`rag-assistant`**: Espec√≠fico, indica RAG + asistente conversacional
- **`signals-analytics`**: Combina detecci√≥n de se√±ales y analytics
- **`identity-config`**: Combina identidad y configuraci√≥n

---

**Documento creado**: 2025-01-08
**Versi√≥n**: 1.0
**Autor**: Kiro AI Assistant
