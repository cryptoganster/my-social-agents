# Propuesta: Sistema de Chatbot Conversacional con RAG para Crypto

## Contexto

BasÃ¡ndome en la documentaciÃ³n proporcionada y la arquitectura existente del proyecto, propongo crear un **Bounded Context** nuevo para el sistema de chatbot conversacional con capacidades RAG (Retrieval-Augmented Generation).

---

## 1. AnÃ¡lisis de la Arquitectura Actual

### Bounded Contexts Existentes

- âœ… **Content Ingestion** - Implementado (ingesta multi-fuente)
- ğŸš§ **Document Processing** - Planificado (chunking semÃ¡ntico)
- ğŸš§ **Embedding & Indexing** - Planificado (vectorizaciÃ³n)
- ğŸš§ **Retrieval & Re-Ranking** - Planificado (bÃºsqueda hÃ­brida)
- ğŸš§ **Knowledge Query/Chat** - Planificado (Q&A conversacional)
- ğŸš§ **Signals & Analytics** - Planificado (detecciÃ³n de tendencias)
- ğŸš§ **Identity & Configuration** - Planificado (configuraciÃ³n)

### Observaciones Clave

1. Ya existe infraestructura de ingesta robusta
2. La arquitectura sigue Clean Architecture + DDD estrictamente
3. El sistema estÃ¡ diseÃ±ado para ser CLI-first con API headless
4. Hay separaciÃ³n clara entre bounded contexts
5. Infraestructura pluggable (LLMs, embeddings, vector DBs)

---

## 2. Propuesta de Bounded Context: "Conversational Intelligence"

### Nombre Propuesto

**`conversational-intelligence`** (o `conversation` para simplificar)

### JustificaciÃ³n del Nombre

- Refleja la naturaleza conversacional del sistema
- Engloba tanto chat como query intelligence
- Diferencia clara de "Knowledge Query/Chat" (que es mÃ¡s genÃ©rico)
- Alineado con la terminologÃ­a del dominio crypto

### Responsabilidades del Contexto

#### Core Responsibilities

1. **GestiÃ³n de Conversaciones**
   - Crear y mantener sesiones de chat
   - Persistir historial conversacional
   - Gestionar contexto multi-turno
   - Manejar referencias anafÃ³ricas ("eso", "el anterior", etc.)

2. **OrquestaciÃ³n RAG**
   - Coordinar bÃºsqueda semÃ¡ntica (Retrieval)
   - Integrar re-ranking de resultados
   - Construir contexto para el LLM
   - Generar respuestas con citaciones

3. **Query Understanding**
   - Detectar intenciÃ³n del usuario
   - Extraer entidades crypto (tokens, exchanges, eventos)
   - Identificar dimensiÃ³n temporal de la pregunta
   - Reformular queries basÃ¡ndose en historial

4. **Response Generation**
   - Generar respuestas contextualizadas
   - Incluir source attribution
   - Formatear respuestas (markdown, JSON, texto)
   - Controlar longitud y detalle

5. **Conversational Memory**
   - Short-term memory (sesiÃ³n actual)
   - Long-term memory (preferencias, contexto histÃ³rico)
   - Checkpointing de estado conversacional

---

## 3. Arquitectura Propuesta

### 3.1 PatrÃ³n ArquitectÃ³nico

Seguiremos el patrÃ³n **Perplexity-style** con embedding "on the fly":

```
User Query
    â†“
Query Understanding (extract intent, entities, temporal context)
    â†“
History-Aware Retrieval (reformulate query with conversation context)
    â†“
Semantic Search (vector similarity)
    â†“
Re-Ranking (signals-based scoring)
    â†“
Context Assembly (top-K chunks + metadata)
    â†“
LLM Generation (with citations)
    â†“
Response + Sources
```

### 3.2 Capas de Almacenamiento

#### 1. PostgreSQL (Relational)

- Conversaciones (sessions)
- Mensajes (user + assistant)
- Metadata de queries
- Source citations
- User preferences
- Conversation checkpoints

#### 2. Vector DB (Embeddings)

- Chunks indexados (del Document Processing context)
- Embeddings persistidos
- Metadata mÃ­nima (url, title, timestamp, asset_tags)

#### 3. Redis (Cache/Memory)

- Conversational context (short-term)
- Query embeddings temporales
- Retrieved chunks cache
- Rate limiting

### 3.3 IntegraciÃ³n con Otros Contexts

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Conversational Intelligence Context             â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Conversation â”‚  â”‚ Query        â”‚  â”‚ Response     â”‚ â”‚
â”‚  â”‚ Management   â”‚  â”‚ Understandingâ”‚  â”‚ Generation   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                  â”‚                  â”‚
           â†“                  â†“                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Retrieval &      â”‚  â”‚ Embedding &      â”‚  â”‚ Signals &        â”‚
â”‚ Re-Ranking       â”‚  â”‚ Indexing         â”‚  â”‚ Analytics        â”‚
â”‚ Context          â”‚  â”‚ Context          â”‚  â”‚ Context          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ComunicaciÃ³n entre contexts:**

- Domain Events (async)
- Interfaces/Ports (sync)
- Anti-Corruption Layers para servicios externos

---

## 4. Estructura del Bounded Context

```
src/conversation/
â”œâ”€â”€ domain/
â”‚   â”œâ”€â”€ aggregates/
â”‚   â”‚   â”œâ”€â”€ conversation.ts           # Aggregate root
â”‚   â”‚   â””â”€â”€ message.ts                # Entity dentro del aggregate
â”‚   â”‚
â”‚   â”œâ”€â”€ value-objects/
â”‚   â”‚   â”œâ”€â”€ conversation-id.ts
â”‚   â”‚   â”œâ”€â”€ message-role.ts           # user | assistant | system
â”‚   â”‚   â”œâ”€â”€ query-intent.ts           # question | comparison | summary | trend
â”‚   â”‚   â”œâ”€â”€ temporal-context.ts       # now | past | range
â”‚   â”‚   â”œâ”€â”€ crypto-entity.ts          # token, exchange, event
â”‚   â”‚   â””â”€â”€ source-citation.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ interfaces/
â”‚   â”‚   â”œâ”€â”€ repositories/
â”‚   â”‚   â”‚   â”œâ”€â”€ conversation-write.ts
â”‚   â”‚   â”‚   â””â”€â”€ conversation-read.ts
â”‚   â”‚   â”œâ”€â”€ factories/
â”‚   â”‚   â”‚   â””â”€â”€ conversation-factory.ts
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â”œâ”€â”€ llm-provider.ts       # Abstraction for LLM
â”‚   â”‚       â”œâ”€â”€ retrieval-service.ts  # Abstraction for retrieval
â”‚   â”‚       â””â”€â”€ memory-service.ts     # Abstraction for memory
â”‚   â”‚
â”‚   â”œâ”€â”€ read-models/
â”‚   â”‚   â”œâ”€â”€ conversation-summary.ts
â”‚   â”‚   â”œâ”€â”€ message-history.ts
â”‚   â”‚   â””â”€â”€ query-result.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ query-understanding.ts    # Extract intent, entities, temporal
â”‚   â”‚   â”œâ”€â”€ context-builder.ts        # Build LLM context from retrieved docs
â”‚   â”‚   â”œâ”€â”€ response-formatter.ts     # Format responses with citations
â”‚   â”‚   â””â”€â”€ conversation-memory.ts    # Manage conversational memory
â”‚   â”‚
â”‚   â””â”€â”€ events/
â”‚       â”œâ”€â”€ conversation-started.ts
â”‚       â”œâ”€â”€ message-sent.ts
â”‚       â”œâ”€â”€ query-processed.ts
â”‚       â””â”€â”€ response-generated.ts
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ commands/
â”‚   â”‚   â”œâ”€â”€ start-conversation/
â”‚   â”‚   â”‚   â”œâ”€â”€ command.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ handler.ts
â”‚   â”‚   â”‚   â””â”€â”€ result.ts
â”‚   â”‚   â”œâ”€â”€ send-message/
â”‚   â”‚   â”‚   â”œâ”€â”€ command.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ handler.ts
â”‚   â”‚   â”‚   â””â”€â”€ result.ts
â”‚   â”‚   â””â”€â”€ end-conversation/
â”‚   â”‚       â”œâ”€â”€ command.ts
â”‚   â”‚       â”œâ”€â”€ handler.ts
â”‚   â”‚       â””â”€â”€ result.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ queries/
â”‚   â”‚   â”œâ”€â”€ get-conversation-history/
â”‚   â”‚   â”‚   â”œâ”€â”€ query.ts
â”‚   â”‚   â”‚   â””â”€â”€ handler.ts
â”‚   â”‚   â”œâ”€â”€ get-active-conversations/
â”‚   â”‚   â”‚   â”œâ”€â”€ query.ts
â”‚   â”‚   â”‚   â””â”€â”€ handler.ts
â”‚   â”‚   â””â”€â”€ search-conversations/
â”‚   â”‚       â”œâ”€â”€ query.ts
â”‚   â”‚       â””â”€â”€ handler.ts
â”‚   â”‚
â”‚   â””â”€â”€ events/
â”‚       â””â”€â”€ message-sent/
â”‚           â”œâ”€â”€ handler.ts            # Trigger retrieval + generation
â”‚           â””â”€â”€ index.ts
â”‚
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ persistence/
â”‚   â”‚   â”œâ”€â”€ entities/
â”‚   â”‚   â”‚   â”œâ”€â”€ conversation.entity.ts
â”‚   â”‚   â”‚   â””â”€â”€ message.entity.ts
â”‚   â”‚   â”œâ”€â”€ repositories/
â”‚   â”‚   â”‚   â”œâ”€â”€ typeorm-conversation-write.ts
â”‚   â”‚   â”‚   â””â”€â”€ conversation-read.ts
â”‚   â”‚   â””â”€â”€ factories/
â”‚   â”‚       â””â”€â”€ typeorm-conversation-factory.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ openai-provider.ts        # OpenAI implementation
â”‚   â”‚   â”œâ”€â”€ anthropic-provider.ts     # Claude implementation
â”‚   â”‚   â””â”€â”€ ollama-provider.ts        # Local LLM implementation
â”‚   â”‚
â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â”œâ”€â”€ redis-memory.ts           # Redis-based memory
â”‚   â”‚   â””â”€â”€ in-memory.ts              # In-memory for testing
â”‚   â”‚
â”‚   â””â”€â”€ adapters/
â”‚       â”œâ”€â”€ retrieval-adapter.ts      # Connects to Retrieval context
â”‚       â””â”€â”€ embedding-adapter.ts      # Connects to Embedding context
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ cli/
â”‚   â”‚   â””â”€â”€ commands/
â”‚   â”‚       â”œâ”€â”€ chat.command.ts       # Interactive chat
â”‚   â”‚       â”œâ”€â”€ ask.command.ts        # Single query
â”‚   â”‚       â””â”€â”€ history.command.ts    # View history
â”‚   â”‚
â”‚   â””â”€â”€ http/
â”‚       â”œâ”€â”€ controllers/
â”‚       â”‚   â””â”€â”€ conversation.controller.ts
â”‚       â””â”€â”€ dto/
â”‚           â”œâ”€â”€ start-conversation.dto.ts
â”‚           â”œâ”€â”€ send-message.dto.ts
â”‚           â””â”€â”€ conversation-response.dto.ts
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ conversation-config.ts
â”‚
â”œâ”€â”€ migrations/
â”‚   â””â”€â”€ 1704000000002-CreateConversationTables.ts
â”‚
â”œâ”€â”€ index.ts
â””â”€â”€ conversation.module.ts
```

---

## 5. Agregados y Entidades Clave

### 5.1 Conversation (Aggregate Root)

```typescript
export class Conversation extends AggregateRoot<string> {
  private _userId: string;
  private _messages: Message[];
  private _status: ConversationStatus;
  private _metadata: ConversationMetadata;
  private _createdAt: Date;
  private _updatedAt: Date;

  // Business methods
  start(userId: string): void
  sendMessage(content: string, role: MessageRole): void
  end(): void
  addContext(context: ConversationalContext): void

  // Invariants
  - Cannot send message if conversation is ended
  - Messages must alternate between user and assistant
  - Must have at least one message to be valid
}
```

### 5.2 Message (Entity)

```typescript
export class Message {
  private _id: string;
  private _conversationId: string;
  private _role: MessageRole;
  private _content: string;
  private _citations: SourceCitation[];
  private _metadata: MessageMetadata;
  private _timestamp: Date;
}
```

### 5.3 Value Objects

#### QueryIntent

```typescript
export class QueryIntent extends ValueObject {
  type: 'question' | 'comparison' | 'summary' | 'trend' | 'explanation';
  confidence: number;
  entities: CryptoEntity[];
  temporalContext: TemporalContext;
}
```

#### SourceCitation

```typescript
export class SourceCitation extends ValueObject {
  sourceId: string;
  sourceType: SourceType;
  url: string;
  title: string;
  snippet: string;
  relevanceScore: number;
  timestamp: Date;
}
```

---

## 6. Flujo de Procesamiento (RAG Pipeline)

### 6.1 Flujo Completo

```typescript
// 1. User sends message
const conversation = await conversationFactory.load(conversationId);
conversation.sendMessage(userMessage, MessageRole.USER);

// 2. Query Understanding
const queryIntent = await queryUnderstandingService.analyze(userMessage, conversation.getHistory());

// 3. History-Aware Retrieval
const reformulatedQuery = await contextBuilder.reformulateQuery(
  userMessage,
  conversation.getHistory(),
);

// 4. Semantic Search (via Retrieval context)
const retrievedChunks = await retrievalService.search({
  query: reformulatedQuery,
  filters: {
    temporal: queryIntent.temporalContext,
    entities: queryIntent.entities,
  },
  topK: 10,
});

// 5. Re-Ranking (via Signals context)
const rerankedChunks = await rerankingService.rerank(retrievedChunks, queryIntent);

// 6. Context Assembly
const llmContext = await contextBuilder.buildContext(
  rerankedChunks.slice(0, 5),
  conversation.getHistory(),
);

// 7. LLM Generation
const response = await llmProvider.generate({
  systemPrompt: CRYPTO_ASSISTANT_PROMPT,
  context: llmContext,
  query: userMessage,
  history: conversation.getHistory(),
});

// 8. Format Response with Citations
const formattedResponse = await responseFormatter.format(response, rerankedChunks.slice(0, 5));

// 9. Save assistant message
conversation.sendMessage(formattedResponse, MessageRole.ASSISTANT);
await conversationRepository.save(conversation);
```

---

## 7. IntegraciÃ³n con LangChain

### 7.1 Uso de LangChain

Usaremos **LangChain** como framework de orquestaciÃ³n, pero manteniendo Clean Architecture:

```typescript
// Domain Interface
export interface ILLMProvider {
  generate(params: GenerationParams): Promise<string>;
  stream(params: GenerationParams): AsyncIterable<string>;
}

// Infrastructure Implementation
@Injectable()
export class LangChainLLMProvider implements ILLMProvider {
  private llm: ChatOpenAI;
  private chain: RunnableSequence;

  constructor() {
    this.llm = new ChatOpenAI({
      model: 'gpt-4o-mini',
      temperature: 0.2,
    });

    // Create history-aware retriever chain
    this.chain = this.buildChain();
  }

  private buildChain(): RunnableSequence {
    const contextualizePrompt = ChatPromptTemplate.fromMessages([
      ['system', CONTEXTUALIZE_SYSTEM_PROMPT],
      ['placeholder', '{chat_history}'],
      ['human', '{input}'],
    ]);

    const qaPrompt = ChatPromptTemplate.fromMessages([
      ['system', QA_SYSTEM_PROMPT],
      ['placeholder', '{chat_history}'],
      ['human', '{input}'],
    ]);

    return createRetrievalChain(
      createHistoryAwareRetriever(this.llm, retriever, contextualizePrompt),
      createStuffDocumentsChain(this.llm, qaPrompt),
    );
  }

  async generate(params: GenerationParams): Promise<string> {
    const result = await this.chain.invoke({
      input: params.query,
      chat_history: params.history,
      context: params.context,
    });

    return result.answer;
  }
}
```

### 7.2 Componentes LangChain a Usar

1. **LCEL (LangChain Expression Language)** - Para pipelines
2. **ChatPromptTemplate** - Para prompts estructurados
3. **create_history_aware_retriever** - Para reformulaciÃ³n de queries
4. **create_retrieval_chain** - Para RAG pipeline
5. **MemorySaver** - Para checkpointing conversacional
6. **Streaming** - Para respuestas en tiempo real

---

## 8. Estrategias de OptimizaciÃ³n

### 8.1 BÃºsqueda HÃ­brida

- Combinar bÃºsqueda semÃ¡ntica (vectores) + keyword (BM25)
- Implementar en el Retrieval context
- Ãštil para nombres exactos de tokens, exchanges

### 8.2 Multi-Query Retrieval

- Generar 3 variaciones de la misma pregunta
- Buscar todas y combinar resultados Ãºnicos
- Ãštil para queries ambiguas

### 8.3 Re-Ranking con Cohere

- Usar Cohere Rerank API
- Reordenar top-10 a top-5 mÃ¡s relevantes
- Aumenta precisiÃ³n dramÃ¡ticamente

### 8.4 Caching Inteligente

- Cache de embeddings de queries frecuentes
- Cache de retrieved chunks por query
- TTL basado en temporalidad del contenido

---

## 9. CLI Commands

### 9.1 Interactive Chat

```bash
npm run cli chat:start
# Inicia sesiÃ³n interactiva
# Mantiene contexto conversacional
# Muestra fuentes citadas
# Permite comandos especiales (/history, /clear, /exit)
```

### 9.2 Single Query

```bash
npm run cli chat:ask "Â¿QuÃ© pasÃ³ con Bitcoin esta semana?"
# Query Ãºnica sin contexto conversacional
# Respuesta con citaciones
# Output en texto, JSON o markdown
```

### 9.3 History Management

```bash
npm run cli chat:history
npm run cli chat:history --conversation-id abc123
npm run cli chat:export --format json
```

---

## 10. Consideraciones de ImplementaciÃ³n

### 10.1 Fases de Desarrollo

#### Fase 1: MVP (Core RAG)

- âœ… Conversation aggregate
- âœ… Basic query understanding
- âœ… Integration with Retrieval context
- âœ… LLM provider (OpenAI)
- âœ… CLI interactive chat
- âœ… Source citations

#### Fase 2: Advanced Features

- âœ… Multi-query retrieval
- âœ… Re-ranking
- âœ… Streaming responses
- âœ… Conversation memory (Redis)
- âœ… HTTP API

#### Fase 3: Optimization

- âœ… Hybrid search
- âœ… Caching strategies
- âœ… Multiple LLM providers
- âœ… Advanced query understanding
- âœ… Conversation analytics

### 10.2 Dependencias Externas

```json
{
  "dependencies": {
    "langchain": "^0.3.0",
    "@langchain/openai": "^0.3.0",
    "@langchain/anthropic": "^0.3.0",
    "@langchain/community": "^0.3.0",
    "zod": "^3.22.0",
    "commander": "^12.0.0",
    "ink": "^4.0.0",
    "redis": "^4.6.0"
  }
}
```

---

## 11. MÃ©tricas y Observabilidad

### 11.1 MÃ©tricas Clave

- Latencia de respuesta (p50, p95, p99)
- Calidad de retrieval (precision@k, recall@k)
- Relevancia de respuestas (RAGAS metrics)
- Tasa de citaciones correctas
- Conversaciones activas
- Mensajes por conversaciÃ³n

### 11.2 Herramientas

- **LangSmith** - Tracing completo de chains
- **RAGAS** - EvaluaciÃ³n automÃ¡tica de RAG
  - Faithfulness (respuesta basada en contexto)
  - Answer Relevance (responde lo preguntado)
  - Context Precision
  - Context Recall

---

## 12. Testing Strategy

### 12.1 Unit Tests

- Domain logic (aggregates, value objects, services)
- Query understanding
- Context building
- Response formatting

### 12.2 Integration Tests

- RAG pipeline completo
- LLM provider integration
- Retrieval context integration
- Memory persistence

### 12.3 Property-Based Tests

- Conversation invariants
- Message ordering
- Citation consistency

### 12.4 Golden Tests

- Respuestas esperadas para queries conocidas
- RegresiÃ³n de calidad

---

## 13. Seguridad

### 13.1 Prompt Injection Protection

- SanitizaciÃ³n de inputs
- System prompts protegidos
- ValidaciÃ³n de comandos especiales

### 13.2 Rate Limiting

- Por usuario
- Por conversaciÃ³n
- Por endpoint API

### 13.3 Data Privacy

- No persistir datos sensibles
- EncriptaciÃ³n de conversaciones (opcional)
- RetenciÃ³n configurable

---

## 14. PrÃ³ximos Pasos

### Paso 1: ValidaciÃ³n de Propuesta

- Revisar bounded context propuesto
- Validar nombres y responsabilidades
- Ajustar estructura si es necesario

### Paso 2: Crear Spec (Requirements)

- Definir user stories
- Definir acceptance criteria (EARS format)
- Identificar dependencias con otros contexts

### Paso 3: DiseÃ±o Detallado

- Definir aggregates y value objects
- Definir interfaces y contratos
- Definir correctness properties (PBT)

### Paso 4: ImplementaciÃ³n Incremental

- Fase 1: MVP
- Fase 2: Advanced features
- Fase 3: Optimization

---

## 15. Preguntas para DiscusiÃ³n

1. **Nombre del Bounded Context**: Â¿Te parece bien "conversational-intelligence" o prefieres otro nombre?

2. **Alcance del MVP**: Â¿Empezamos con chat interactivo CLI o tambiÃ©n incluimos API HTTP desde el inicio?

3. **LLM Provider**: Â¿Empezamos solo con OpenAI o implementamos mÃºltiples providers desde el inicio?

4. **Vector DB**: Â¿QuÃ© vector DB prefieres? (Qdrant, Pinecone, Weaviate, pgvector)

5. **Memoria Conversacional**: Â¿Redis desde el inicio o empezamos con in-memory?

6. **IntegraciÃ³n con Contexts Existentes**: Â¿Necesitamos implementar primero Document Processing, Embedding & Indexing, y Retrieval contexts, o podemos mockearlos inicialmente?

---

## ConclusiÃ³n

Esta propuesta define un bounded context robusto y bien estructurado para el sistema de chatbot conversacional, siguiendo estrictamente los principios de Clean Architecture y DDD del proyecto. La arquitectura es modular, extensible y permite implementaciÃ³n incremental.

Â¿QuÃ© te parece? Â¿Hay algo que quieras ajustar antes de proceder con la creaciÃ³n del spec formal?
